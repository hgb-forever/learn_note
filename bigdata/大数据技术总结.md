# **2019-2020学年第2学期《大数据开发技术》**

​																			课程总结报告

​													学号：  20170862107       姓名：黄国彪

# 一、大数据开发技术框架

![image-20200622154755669](C:\Users\甘正\AppData\Roaming\Typora\typora-user-images\image-20200622154755669.png)



# 二、大数据开发技术总结

## 1.hadoop的三种模式

- 本地模式（Local，测试环境）
- 伪分布式（测试环境）
- 完全分布式（开发环境）

## 2、hadoop集群

> hadoop有三大发行版本，Apache版本最原始（最基础）的版本，对于入门学习最好。Cloudera在大型互联网企业中用的较多。Hortonworks文档较好。
>
> 这里我们选择的是Apache版本

![image-20200403171116746](C:\Users\甘正\AppData\Roaming\Typora\typora-user-images\image-20200403171116746.png)

这里我们学习的是2.x版本的



### 1）hdfs架构

HDFS（Hadoop Distributed File System）的架构概述

- 1.Namenode    -----Master
- 2.DataNode      -------Slave
- 3.Secondary NameNode——存档
- 4.Client
- 5.块大小block的合理设置
- 6.hadoop的shell和客户端操作（bin/hadoop fs -ls/-put/-get...）
- 7.小文件归档（bin/hadoop archive -archiveName input.har –p  /user/atguigu/input   /user/atguigu/output）
- 8.回收站，启用回收站防止误删（fs.trash.interval）
- 9.快照，开启指定目录的快照，相当于对目录做备份（hdfs dfs -createSnapshot /user/atguigu/input）
- 10.高可用HA，依赖于zookeeper集群，将NameNode组装成一个集群

### 2）Yarn架构

- 1.ResourceManager    CEO
- 2.NodeManager   项目经理
- 3.ApplicationMaster   项目员工
- 4.Container    相当于虚拟机
- 5.Driver 真正的执行计算任务

![image-20200403173242610](C:\Users\甘正\AppData\Roaming\Typora\typora-user-images\image-20200403173242610.png)

![image-20200702204934505](C:\Users\甘正\AppData\Roaming\Typora\typora-user-images\image-20200702204934505.png)

### 3）MapReduce架构

- Mr Appmaster：负责整个程序的过程调度和状态协调
- Map Task：负责Map阶段的整个数据处理流程
- Reduce Task：扶着Reduce阶段的整个数据处理流程
- MapReduce编程需要实现三个部分，Mapper、Reducer和Driver

![img](file:///C:\Users\甘正\AppData\Local\Temp\ksohtml16860\wps1.png)

![img](file:///C:\Users\甘正\AppData\Local\Temp\ksohtml16860\wps2.png)

## 3、zookeeper

zookeeper集群可以保存服务的数据、状态、副本。可以看成其他服务的统一集群管理者。

是由一个leader和多个follower组成的集群。利用心跳机制获取follower的状态，leader有半数选举产生

特点：有序、一致、原子、实时。

数据结构是树形结构。

两种节点类型：

1.Persistent（持久）：客户端和服务器断开后，创建的节点不删除

2.Ephemeral（短暂）：客户端和服务器断开后，创建的节点自己删除



## 4.Flume

Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统。Flume基于流式架构，灵活简单

![image-20200409095340448](C:\Users\甘正\AppData\Roaming\Typora\typora-user-images\image-20200409095340448.png)

![image-20200409095403181](C:\Users\甘正\AppData\Roaming\Typora\typora-user-images\image-20200409095403181.png)

应用方法：

编写配置文件，可从官网复制

开启flume

```
bin/flume-ng agent --conf conf/ --name a1 --conf-file job/flume-telnet-logger.conf -Dflume.root.logger=INFO,console
```



## 5.kafka

Kafka 是一个分布式的基于**发布**/**订阅**模式的**消息队列**（Message Queue），主要应用于大数据实时处理领域。![image-20200413152901867](C:\Users\甘正\AppData\Roaming\Typora\typora-user-images\image-20200413152901867.png)

两种模式：

- 点对点模式，消息发送一对一
- 发布/订阅模式，一对多

![image-20200413155018412](C:\Users\甘正\AppData\Roaming\Typora\typora-user-images\image-20200413155018412.png)

![image-20200413163420554](C:\Users\甘正\AppData\Roaming\Typora\typora-user-images\image-20200413163420554.png)



## 6.Hive

Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类SQL查询功能。

本质是：将HQL转化成MapReduce程序

![img](file:///C:\Users\甘正\AppData\Local\Temp\ksohtml16860\wps3.png)

1）Hive处理的数据存储在HDFS

2）Hive分析数据底层的实现是MapReduce

3）执行程序运行在Yarn上

## 7.sqoop

将导入或导出命令翻译成mapreduce程序来实现，只有map阶段。

在翻译出的mapreduce中主要是对inputformat和outputformat进行定制。

主要用于在Hadoop(Hive)与传统的数据库(mysql、postgresql...)间进行数据的传递。



## 8.Presto和Druid

均用于实现实时业务查询和实时指标的分析

![image-20200414223958746](C:\Users\甘正\AppData\Roaming\Typora\typora-user-images\image-20200414223958746.png)

Druid按照时间线进行分片索引，速度较快。

Presto基于内存速度也较快，而且支持的源多



## 9.spark和scala

![image-20200702202859556](C:\Users\甘正\AppData\Roaming\Typora\typora-user-images\image-20200702202859556.png)

scala：

1. Scala是Scalable Language的简写，是一门多范式的编程语言。
2. Spark新一代内存级大数据计算框架，是大数据的重要内容。
3. Scala是一门以JVM为运行环境并将面向对象编程和函数式编程的最佳特性结合在一起的静态型编程语言。

![img](file:///C:\Users\甘正\AppData\Local\Temp\ksohtml8116\wps2.png)

spark：

- Spark是一种基于内存的快速、通用、可扩展的大数据分析引擎
- RDD是spark的最基本的数据抽象
- spark的扩展工具，spark core / spark sql / spark streaming(逐渐被Structure streaming代替)  / spark mlib(机器学习库)  / spark graphx(图计算引擎)

![image-20200702205835949](C:\Users\甘正\AppData\Roaming\Typora\typora-user-images\image-20200702205835949.png)

# 三、大数据项目开发总结

项目开发基本流程：

首先应该确定项目架构的设计和项目需求，涉及到的技术有哪些和要用什么版本，都要先确定下来。

其次，应该设计项目流程图，不仅能对项目有个大概的认识，而且开发过程中有很大的指导作用，也方便与排错

接下来就是对数据源的定义。两个项目均使用模拟数据，这里不过多描述。总之拿到了数据之后，就可以多数据进行相应的操作。大数据数仓项目主要是为了对数仓中的数据进行报表分析，于是flume采集到日志文件后交给kafka保证输入和输出的相对速率再交给flume保存到hdfs上，mysql上的业务日志通过sqoop上传到hdfs，hdfs上的数据再交给hive进行离线分析，最终返回给前端页面展示，presto和druid提供实时计算。

而电商项目主要是通过分析用户行为，返回给用户推荐的产品。使用mongdb存储用户日志，使用spark读取mongdb中的数据，进行相应操作后再保存到mongdb和redis。使用kafka sreaming提供实时计算。前端页面访问mongdb和redis展示离线和实时计算结果。