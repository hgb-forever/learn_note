# 选择框架

![img](file:///C:\Users\甘正\AppData\Local\Temp\ksohtml\wps9C9C.tmp.png)

![img](file:///C:\Users\甘正\AppData\Local\Temp\ksohtml\wpsEB.tmp.png)

![img](file:///C:\Users\甘正\AppData\Local\Temp\ksohtml\wps54C9.tmp.png)

![img](file:///C:\Users\甘正\AppData\Local\Temp\ksohtml\wps7784.tmp.png)

![img](file:///C:\Users\甘正\AppData\Local\Temp\ksohtml\wpsB1B0.tmp.png)

![img](file:///C:\Users\甘正\AppData\Local\Temp\ksohtml\wps9100.tmp.png)

​	测试集群服务器规划

| 服务名称              | 子服务           | 服务器hadoop102 | 服务器hadoop103 | 服务器hadoop104 |
| --------------------- | ---------------- | --------------- | --------------- | --------------- |
| HDFS                  | NameNode         | √               |                 |                 |
| DataNode              | √                | √               | √               |                 |
| SecondaryNameNode     |                  |                 | √               |                 |
| Yarn                  | NodeManager      | √               | √               | √               |
| Resourcemanager       |                  | √               |                 |                 |
| Zookeeper             | Zookeeper Server | √               | √               | √               |
| Flume(采集日志)       | Flume            | √               | √               |                 |
| Kafka                 | Kafka            | √               | √               | √               |
| Flume（消费Kafka）    | Flume            |                 |                 | √               |
| Hive                  | Hive             | √               |                 |                 |
| MySQL                 | MySQL            | √               |                 |                 |
| Sqoop                 | Sqoop            | √               |                 |                 |
| Presto                | Coordinator      | √               |                 |                 |
| Worker                |                  | √               | √               |                 |
| Azkaban               | AzkabanWebServer | √               |                 |                 |
| AzkabanExecutorServer | √                |                 |                 |                 |
| Druid                 | Druid            | √               | √               | √               |
| 服务数总计            |                  | 13              | 8               | 9               |

# 做集群前先关闭防火墙！！！

# hadoop集群部署

配置jdk并写入/etc/profile文件中

下载安装hadoop并配置8个文件(hadoop-env.sh,core-site.xml,yarn-env.sh,yarn-site.xml,hdfs-site.xml,mapred-env.sh,mapred-site.xml,**slave**)

## 多目录存储

为了保证hdfs存储空间足够，应在hdfs-site.sh里面配置多目录存储。

```xml
<property>
    <name>dfs.datanode.data.dir</name>
<value>file:///${hadoop.tmp.dir}/dfs/data1,file:///hd2/dfs/data2,file:///hd3/dfs/data3,file:///hd4/dfs/data4</value>
</property>
```

## 三大架构

### HDFS

hadoop的文件存储系统，包括NameNode（主管）、DataNode（员工）、SecondaryNameNode（秘书）以及客户端（客户）

### Yarn

hadoop的资源调度者，包括ResourceManager（CEO）、NodeManager（项目经理）、ApplicationMaster （项目员工）、Container（会虚拟化的打工仔，如内存、cpu，是一个资源抽象）

![image-20200403173242610](C:\Users\甘正\AppData\Roaming\Typora\typora-user-images\image-20200403173242610.png)

### MapReduce

MapReduce将计算过程分为两个阶段：Map和Reduce，Map阶段里有MapTask，Reduce阶段里有ReduceTask，具体工作过程自行百度，提供接口可供用户自行编写MapReduce任务。

## 三种模式

### 单机模式

只能在本机上使用

### 伪分布式

虽说也是集群却只配置了一台机器，用于资源不充足的测试环境下

### 完全分布式

开发重点使用

## 配置hadoop支持多种格式压缩

将编译好的jar包放入hadoop-2.7.2/share/hadoop/common/目录下

修改core-site.xml增加配置支持相应的压缩格式，hadoop checkpoint

同步jar和配置文件到集群。hadoop参数调优，提升性能。

# 配置zookeeper监控集群资源

在配置zookeeper到集群，修改唯一my.id，并创建zkData目录。

内部

# 生成日志文件

# 采集Flume

下载并解压后修改flume-env.sh，配置jdk环境。

Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统。Flume基于流式架构，灵活简单。

## Flume组成架构

![image-20200409095340448](C:\Users\甘正\AppData\Roaming\Typora\typora-user-images\image-20200409095340448.png)

### Agent

​	Agent是一个JVM进程，它以事件的形式将数据从源头送至目的，是Flume数据传输的基本单元。

​	Agent主要有3个部分组成，Source、Channel、Sink。

**Source**是负责接收数据到Flume Agent的组件。

put事务

**Channel**是位于Source和Sink之间的缓冲区

get事务

**Sink**不断地轮询Channel中的事件且批量地移除它们，并将这些事件批量写入到存储或索引系统、或者被发送到另一个Flume Agent。

![image-20200409101929562](C:\Users\甘正\AppData\Roaming\Typora\typora-user-images\image-20200409101929562.png)

# Kafka

Kafka 是一个分布式的基于**发布**/**订阅**模式的**消息队列**（Message Queue），主要应用于大数据实时处理领域。依赖zookeeper集群保存一些meta信息。

## Kafka框架

![image-20200413152901867](C:\Users\甘正\AppData\Roaming\Typora\typora-user-images\image-20200413152901867.png)

<img src="C:\Users\甘正\AppData\Roaming\Typora\typora-user-images\image-20200413155018412.png" alt="image-20200413155018412" style="zoom: 200%;" />

（1）点对点模式（一对一，消费者主动拉取数据，消息收到后消息清除）

（2）发布/订阅模式（一对多，数据生产后，推送给所有订阅者）

## 配置kafka

主要注意修改唯一broker.id

# hive

Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张表，并提供类SQL查询功能。

**本质是**：将HQL转化成MapReduce程序。

![img](file:///C:\Users\甘正\AppData\Local\Temp\ksohtml\wpsC9CD.tmp.png)

1）Hive处理的数据存储在HDFS

2）Hive分析数据底层的实现是MapReduce

3）执行程序运行在Yarn上

## Hive架构原理

![img](file:///C:\Users\甘正\AppData\Local\Temp\ksohtml\wpsA6B1.tmp.png)

## hiveSQL

基本语法和SQL语法差不多。

表的类型：

1. 管理表（默认类型，hive具有所有权限）
2. 外部表（hive认为其不完全拥有这份数据，删除表只删除元数据）
3. 分区表（Hive中的分区就是分目录）
4. 分桶表（分区针对的是数据的存储路径；分桶针对的是数据文件。）

配置tez作为hive的计算引擎

## 用户行为数仓搭建

### ods（原始数据层）

不对数据进行任何操作，直接加载源数据

### dwd（明细数据层）

结构和粒度与原来保持一致，对ods的数据进行清洗，去除空值、脏数据、超过极限范围的数据。

### dws（服务数据层）

以dwd层数据为基础，进行轻度汇总。

### ads（数据应用层）

为各种统计报表提供数据

## 业务数仓搭建

### 表的分类

- 实体表（现实存在的业务对象）
- 维度表（编号的解释表。也可以称之为码表）
- 事务型事实表（一旦发生不会再变化）
- 周期型事实表（随着业务发生不断产生的数据）

### 同步策略

Ø 全量表：存储完整的数据。

Ø 增量表：存储新增加的数据。

Ø 新增及变化表：存储新增加的数据和变化的数据。

Ø 拉链表：对新增及变化表做定期合并。

## 关系建模与维度建模

​	关系模型主要应用与OLTP系统中，为了保证数据的一致性以及避免冗余，所以大部分业务系统的表都是遵循第三范式的。

​	维度模型主要应用于OLAP系统中，因为关系模型虽然冗余少，但是在大规模数据，跨表分析统计查询过程中，会造成多表关联，这会大大降低执行效率。

在维度建模的基础上又分为三种模型：星型模型、雪花模型、星座模型

# sqoop

## sqoop原理

将导入或导出命令翻译成mapreduce程序来实现，只有map阶段。

在翻译出的mapreduce中主要是对inputformat和outputformat进行定制。

## sqoop安装

下载并解压，修改配置文件，拷贝JDBC驱动。

# Presto和Druid

均用于实现实时业务查询和实时指标的分析

![image-20200414223958746](C:\Users\甘正\AppData\Roaming\Typora\typora-user-images\image-20200414223958746.png)

Druid按照时间线进行分片索引，速度较快。

Presto基于内存速度也较快，而且支持的源多